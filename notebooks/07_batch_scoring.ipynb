{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee0fcc2",
   "metadata": {},
   "source": [
    "# Batch Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2125f9",
   "metadata": {},
   "source": [
    "This notebook handles batch scoring of all the customers, clusters, such that they are ready for retrieval and can be calculated on beforehand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a69d7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6588c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "765d2432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark core\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import col, explode, year, month, lit, when, row_number, exp\n",
    "from pyspark.sql.functions import sum as _sum\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# MLlib models\n",
    "from pyspark.ml.recommendation import ALSModel\n",
    "from pyspark.ml.feature import StringIndexerModel, StringIndexer, IndexToString\n",
    "\n",
    "\n",
    "# File handling\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acf3e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LocalSparkForTesting\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadd076b",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ae91065",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = os.path.join('/sparkdata/wholesale-recommender','models')\n",
    "\n",
    "# Load models\n",
    "als_model_individual = ALSModel.load(os.path.join(MODELS_PATH, \"individual_cust_rec\"))\n",
    "als_model_clusters = ALSModel.load(os.path.join(MODELS_PATH, \"cluster_cat_rec\"))\n",
    "customer_index_model = StringIndexerModel.load(os.path.join(MODELS_PATH, \"customer_indexer_model\"))\n",
    "product_index_model = StringIndexerModel.load(os.path.join(MODELS_PATH, \"product_indexer_model\"))\n",
    "category_index_model = StringIndexerModel.load(os.path.join(MODELS_PATH, \"category_indexer_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9fc7f",
   "metadata": {},
   "source": [
    "## Recommendations: Individual Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea51e0e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Create dataframe with all customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa7e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('/sparkdata/wholesale-recommender','processed')\n",
    "\n",
    "# Get all unique indexed customer IDs\n",
    "customers = spark.read.parquet(os.path.join(DATA_PATH, \"customers_features\")).withColumnRenamed(\"Customer ID\", \"customer_id\")\n",
    "indexed_customers = customer_index_model.transform(customers.select(\"customer_id\")).select(\"customer_id\", \"customer_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b74e83",
   "metadata": {},
   "source": [
    "### Generate top 10 recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5917ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "\n",
    "recs = als_model_individual.recommendForUserSubset(indexed_customers, top_n)\n",
    "\n",
    "# Explode the array of recommendations\n",
    "recs_individual_exploded = recs.select(\n",
    "    col(\"customer_index\"),\n",
    "    explode(\"recommendations\").alias(\"rec\")\n",
    ").select(\n",
    "    \"customer_index\",\n",
    "    col(\"rec.product_index\").alias(\"product_index\"),\n",
    "    col(\"rec.rating\").alias(\"score\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045b65cf",
   "metadata": {},
   "source": [
    "### Map IDs back to original IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00698d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_lookup = spark.createDataFrame([\n",
    "    Row(customer_index=i, customer_id=cid)\n",
    "    for i, cid in enumerate(customer_index_model.labels)\n",
    "])\n",
    "\n",
    "product_lookup = spark.createDataFrame([\n",
    "    Row(product_index=i, product_id=pid)\n",
    "    for i, pid in enumerate(product_index_model.labels)\n",
    "])\n",
    "\n",
    "# Join to get human-readable IDs\n",
    "recs_individual_exploded = recs_individual_exploded.join(customer_lookup, on=\"customer_index\", how=\"left\")\n",
    "recs_individual_exploded = recs_individual_exploded.join(product_lookup, on=\"product_index\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c91cdc1",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ff0264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output path\n",
    "OUTPUT_PATH = os.path.abspath(os.path.join('/sparkdata/wholesale-recommender', 'results'))\n",
    "\n",
    "# Save top 10 recommendations per customer\n",
    "recs_individual_exploded.write.mode(\"overwrite\").parquet(os.path.join(OUTPUT_PATH,\"customer_individual_recs\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a384adb",
   "metadata": {},
   "source": [
    "## Recommendations: Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad57bee",
   "metadata": {},
   "source": [
    "### Create dataframe with all clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25c5e1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('/sparkdata/wholesale-recommender','processed')\n",
    "\n",
    "# Get all customer clusters\n",
    "clusters = spark.read.parquet(os.path.join(DATA_PATH, \"customer_cluster\")).select(\"cluster\").distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5672d8f",
   "metadata": {},
   "source": [
    "### Generate top 10 recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8efe70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "\n",
    "recs = als_model_clusters.recommendForUserSubset(clusters, top_n)\n",
    "\n",
    "# Explode the array of recommendations\n",
    "recs_clusters_exploded = recs.select(\n",
    "    col(\"cluster\"),\n",
    "    explode(\"recommendations\").alias(\"rec\")\n",
    ").select(\n",
    "    \"cluster\",\n",
    "    col(\"rec.category_index\").alias(\"category_index\"),\n",
    "    col(\"rec.rating\").alias(\"score\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787b0948",
   "metadata": {},
   "source": [
    "### Map IDs back to original IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e5b0054",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_string = IndexToString(inputCol=\"category_index\",\n",
    "                                outputCol=\"category_name\",\n",
    "                                labels=category_index_model.labels)\n",
    "\n",
    "recs_clusters_exploded = index_to_string.transform(recs_clusters_exploded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e19d47",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84d466ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save top 10 recommendations per cluster\n",
    "recs_clusters_exploded.write.mode(\"overwrite\").parquet(os.path.join(OUTPUT_PATH,\"customer_cluster_recs\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe7e9c8",
   "metadata": {},
   "source": [
    "## Popular Items for delivery date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096c2808",
   "metadata": {},
   "source": [
    "### Get all order lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b3849f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('/sparkdata/wholesale-recommender','cleaned')\n",
    "\n",
    "order_lines = spark.read.parquet(os.path.join(DATA_PATH, \"order_lines\")).withColumnRenamed('Date Order was placed', 'order_date').withColumnRenamed('Product ID', 'product_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c14b44",
   "metadata": {},
   "source": [
    "### Get most popular items for month\n",
    "\n",
    "Using time-decayed weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a596253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year and month\n",
    "df = order_lines.withColumn(\"year\", year(\"order_date\")) \\\n",
    "                .withColumn(\"month\", month(\"order_date\"))\n",
    "\n",
    "# Get most recent year\n",
    "max_year = df.agg({\"year\": \"max\"}).collect()[0][0]\n",
    "\n",
    "# Apply time-decay weighting\n",
    "df = df.withColumn(\"year_diff\", lit(max_year) - col(\"year\")) \\\n",
    "       .withColumn(\"decay_weight\", exp(-0.5 * col(\"year_diff\")))\n",
    "\n",
    "# Multiply quantity with decay weight, to weight by quantity\n",
    "df = df.withColumn(\"weighted_qty\", col(\"decay_weight\") * col(\"Quantity Ordered\"))\n",
    "\n",
    "# Aggregate by month and product\n",
    "monthly_popularity = df.groupBy(\"month\", \"product_id\") \\\n",
    "    .agg(_sum(\"weighted_qty\").alias(\"popularity_score\"))\n",
    "\n",
    "# Rank items per month\n",
    "window = Window.partitionBy(\"month\").orderBy(col(\"popularity_score\").desc())\n",
    "\n",
    "# Get top 10 for each month\n",
    "top10_per_month = monthly_popularity.withColumn(\"rank\", row_number().over(window)) \\\n",
    "                                    .filter(col(\"rank\") <= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01180d5",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4226b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_per_month.write.mode(\"overwrite\").parquet(f\"{OUTPUT_PATH}/items_per_month\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
